{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6357ef5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "409d2d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"using {device}\")\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "19b4c7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training text:\n",
      "The quick brown fox jumps over the lazy dog.\n",
      "Hello world, this is a sample text for training.\n",
      "Machine learning is transforming modern technology.\n",
      "Artificial intelligence helps solve complex problems.\n",
      "Python programming language is popular for data science.\n",
      "JavaScript is essential for web development.\n",
      "Mobile applications are becoming more sophisticated every day.\n",
      "Cloud computing provides scalable infrastructure solutions.\n",
      "Data analysis requires careful examination of patterns.\n",
      "Natural language processing enables computers to understand human language.\n",
      "Machine learning models need quality training data.\n",
      "Deep learning architectures include neural networks.\n",
      "Computer vision can identify objects in images.\n",
      "Autonomous vehicles use sensors and algorithms to navigate.\n",
      "Smart home devices respond to voice commands.\n",
      "Virtual reality creates immersive digital experiences.\n",
      "Augmented reality overlays digital information on the real world.\n",
      "Blockchain technology enables secure transactions.\n",
      "Cybersecurity protects systems from digital attacks.\n",
      "Internet of Things connects everyday devices to the network.\n",
      "Software development requires planning and testing.\n",
      "User interface design focuses on user experience.\n",
      "Database management systems store and organize information.\n",
      "Version control helps teams collaborate on code.\n",
      "Agile methodology emphasizes iterative development.\n",
      "Continuous integration automates the build process.\n",
      "Test driven development ensures code quality.\n",
      "Code review improves software reliability.\n",
      "Documentation is essential for maintainable code.\n",
      "Debugging skills are crucial for programmers.\n",
      "The weather today is sunny and warm.\n",
      "I need to go to the grocery store later.\n",
      "Meeting scheduled for tomorrow at two PM.\n",
      "Please send me the report by end of day.\n",
      "Let's discuss this in our next team meeting.\n",
      "Customer feedback is important for improvement.\n",
      "Project deadline is approaching quickly.\n",
      "Team collaboration leads to better results.\n",
      "Time management skills increase productivity.\n",
      "Effective communication prevents misunderstandings.\n",
      "Machine learning algorithms can predict future trends.\n",
      "Data scientists analyze large datasets for insights.\n",
      "Business intelligence tools help make informed decisions.\n",
      "Customer relationship management systems track interactions.\n",
      "Supply chain optimization reduces costs and improves efficiency.\n",
      "Digital marketing strategies target specific audiences.\n",
      "Social media platforms connect people worldwide.\n",
      "E commerce websites facilitate online shopping.\n",
      "Content management systems make website updates easier.\n",
      "Search engine optimization improves website visibility.\n",
      "I love reading books in my free time.\n",
      "Music helps me relax after a long day.\n",
      "Exercise is important for physical health.\n",
      "Cooking delicious meals is a enjoyable hobby.\n",
      "Traveling exposes you to different cultures.\n",
      "Learning new skills keeps the mind sharp.\n",
      "Photography captures precious moments.\n",
      "Gardening connects you with nature.\n",
      "Writing helps organize thoughts and ideas.\n",
      "Painting allows creative expression.\n",
      "The company announced quarterly earnings today.\n",
      "Stock market fluctuations affect investment portfolios.\n",
      "Economic indicators help predict market trends.\n",
      "Financial planning ensures long term stability.\n",
      "Risk management identifies potential threats.\n",
      "Budget allocation determines resource distribution.\n",
      "Cost benefit analysis evaluates project viability.\n",
      "Return on investment measures financial performance.\n",
      "Market research identifies customer needs.\n",
      "Competitive analysis informs business strategy.\n",
      "Renewable energy sources include solar and wind power.\n",
      "Environmental conservation protects natural resources.\n",
      "Climate change requires global cooperation.\n",
      "Sustainable development balances growth and ecology.\n",
      "Green technology reduces environmental impact.\n",
      "Electric vehicles decrease carbon emissions.\n",
      "Energy efficiency lowers operational costs.\n",
      "Waste management promotes recycling and reuse.\n",
      "Water conservation preserves vital resources.\n",
      "Biodiversity maintains ecosystem health.\n",
      "Education provides opportunities for personal growth.\n",
      "Online learning platforms make education accessible.\n",
      "Critical thinking skills are valuable in every field.\n",
      "Problem solving abilities help overcome challenges.\n",
      "Collaboration fosters innovation and creativity.\n",
      "Mentorship accelerates professional development.\n",
      "Lifelong learning adapts to changing requirements.\n",
      "Knowledge sharing builds stronger organizations.\n",
      "Research advances human understanding.\n",
      "Experimentation leads to new discoveries.\n",
      "Healthcare technology improves patient outcomes.\n",
      "Medical research develops new treatments and cures.\n",
      "Preventive care reduces healthcare costs.\n",
      "Mental health awareness promotes overall wellbeing.\n",
      "Fitness tracking monitors physical activity.\n",
      "Nutrition science informs dietary choices.\n",
      "Sleep quality affects daily performance.\n",
      "Stress management techniques improve quality of life.\n",
      "Work life balance ensures long term satisfaction.\n",
      "Personal development leads to fulfillment.\n",
      "How are you doing today?\n",
      "I'll be there in a few minutes.\n",
      "What time should we meet?\n",
      "Let me know if you need anything.\n",
      "Thanks for your help with this.\n",
      "I really appreciate your support.\n",
      "Have a great day ahead!\n",
      "Looking forward to seeing you soon.\n",
      "Can you please send me the file?\n",
      "Let's catch up over coffee sometime.\n",
      "Just checking in to see how you're doing.\n",
      "I'll get back to you on that.\n",
      "Please keep me updated on the progress.\n",
      "Sorry for the late reply.\n",
      "No problem at all!\n",
      "That sounds good to me.\n",
      "What do you think about this?\n",
      "Let me double check and confirm.\n",
      "I'm running a bit late.\n",
      "See you later this evening.\n",
      "Happy birthday to you!\n",
      "Congratulations on your achievement.\n",
      "Well done on the presentation.\n",
      "I'm proud of your hard work.\n",
      "Make yourself at home.\n",
      "Drive safely on your way.\n",
      "Take care of yourself.\n",
      "Call me when you're free.\n",
      "Text me when you arrive.\n",
      "I'm here if you need me.\n",
      "How's everything going?\n",
      "Long time no see!\n",
      "What's new with you?\n",
      "Same here, me too.\n",
      "I know what you mean.\n",
      "That makes sense to me.\n",
      "I understand how you feel.\n",
      "Let's agree to disagree.\n",
      "No worries about it.\n",
      "You're welcome anytime.\n",
      "My pleasure to help.\n",
      "Anytime you need assistance.\n",
      "I'm just kidding around.\n",
      "Just pulling your leg.\n",
      "Better late than never.\n",
      "Take your time with it.\n",
      "No rush on this one.\n",
      "Whenever you're ready.\n",
      "Let's play it by ear.\n",
      "We'll figure it out.\n",
      "That's a great idea!\n",
      "I like your thinking.\n",
      "You're absolutely right.\n",
      "I couldn't agree more.\n",
      "That's exactly right.\n",
      "You read my mind.\n",
      "Great minds think alike.\n",
      "Speak of the devil!\n",
      "Small world, isn't it?\n",
      "It's good to see you.\n",
      "What's for dinner tonight?\n",
      "I'm starving right now.\n",
      "This tastes delicious!\n",
      "You're a great cook.\n",
      "Could you pass the salt?\n",
      "I'm full, thank you.\n",
      "Let's clean up together.\n",
      "I'll do the dishes.\n",
      "You take out the trash.\n",
      "Time for bed soon.\n",
      "I'm exhausted today.\n",
      "Sleep well tonight.\n",
      "Sweet dreams to you.\n",
      "Good morning sunshine!\n",
      "Rise and shine everyone.\n",
      "Time to wake up now.\n",
      "I need more coffee.\n",
      "Running on caffeine today.\n",
      "Another busy day ahead.\n",
      "Let's get this done.\n",
      "We can do this!\n",
      "Almost finished now.\n",
      "Just one more thing.\n",
      "Last but not least.\n",
      "In the nick of time.\n",
      "Better safe than sorry.\n",
      "Safety first always.\n",
      "Health is wealth indeed.\n",
      "Money can't buy happiness.\n",
      "Family comes first always.\n",
      "I'm so happy for you.\n",
      "That's wonderful news!\n",
      "You deserve the best.\n",
      "Keep up the good work.\n",
      "Don't give up now.\n",
      "You're almost there.\n",
      "I believe in you.\n",
      "You can do it!\n",
      "Go for your dreams.\n",
      "Follow your passion.\n",
      "Live your best life.\n",
      "Take it easy today.\n",
      "Don't work too hard.\n",
      "Enjoy the little things.\n",
      "Stop and smell roses.\n",
      "Life is too short.\n",
      "Tomorrow is another day.\n",
      "Every cloud has silver lining.\n",
      "When life gives lemons.\n",
      "The more the merrier.\n",
      "The early bird catches worm.\n",
      "Practice makes perfect.\n",
      "Honesty is best policy.\n",
      "Actions speak louder.\n",
      "Home sweet home indeed.\n",
      "There's no place like home.\n",
      "East west home best.\n",
      "Cleanliness is next to godliness.\n",
      "Early to bed early to rise.\n",
      "A penny saved is earned.\n",
      "Could you help me please?\n",
      "I need a favor.\n",
      "Would you mind helping?\n",
      "Of course I can help.\n",
      "I'd be happy to assist.\n",
      "Let me know how I can help.\n",
      "Thanks so much again!\n",
      "You're too kind really.\n",
      "Don't mention it please.\n",
      "It was nothing really.\n",
      "After you, please go ahead.\n",
      "Age before beauty they say.\n",
      "Ladies first always.\n",
      "You look nice today.\n",
      "I like your outfit.\n",
      "Nice to meet you!\n",
      "Pleased to make acquaintance.\n",
      "Likewise I'm sure.\n",
      "The pleasure is mine.\n",
      "Until we meet again.\n",
      "See you tomorrow then.\n",
      "Talk to you later.\n",
      "Have a good one!\n",
      "Take it easy now.\n",
      "You too, same to you.\n",
      "Bless you for sneeze.\n",
      "Excuse me pardon me.\n",
      "Sorry about that.\n",
      "My apologies again.\n",
      "Forgive my mistake.\n",
      "It's cold outside today.\n",
      "Hot enough for you?\n",
      "Nice weather we're having.\n",
      "Rainy day today huh?\n",
      "I love sunny days.\n",
      "Beautiful sunset tonight.\n",
      "The moon looks amazing.\n",
      "Stars are bright tonight.\n",
      "Seasons are changing now.\n",
      "Spring is in the air.\n",
      "Summer heat is coming.\n",
      "Fall colors are beautiful.\n",
      "Winter is approaching fast.\n",
      "Happy holidays everyone!\n",
      "Merry Christmas to all!\n",
      "Happy New Year folks!\n",
      "Happy Thanksgiving day!\n",
      "Enjoy the celebration!\n",
      "Party time has come.\n",
      "Let's have some fun.\n",
      "Make some memories today.\n",
      "Capture this moment please.\n",
      "Smile for the camera!\n",
      "Say cheese everyone!\n",
      "Perfect picture this is.\n",
      "Priceless memory made.\n",
      "Good times with friends.\n",
      "Making memories together.\n",
      "Friends are family chosen.\n",
      "I'm learning something new.\n",
      "Practice makes perfect.\n",
      "Never stop learning.\n",
      "Knowledge is power indeed.\n",
      "Reading expands the mind.\n",
      "Education is important.\n",
      "Curiosity leads to discovery.\n",
      "Ask questions to learn.\n",
      "Mistakes help us grow.\n",
      "Failure leads to success.\n",
      "Try try again always.\n",
      "Perseverance pays off.\n",
      "Patience is virtue.\n",
      "Good things take time.\n",
      "Rome wasn't built day.\n",
      "Slow and steady wins.\n",
      "Quality over quantity.\n",
      "Less is more sometimes.\n",
      "Simple is beautiful.\n",
      "Beauty is in eye.\n",
      "Love is blind they say.\n",
      "Absence makes heart grow.\n",
      "Distance means so little.\n",
      "True friendship lasts forever.\n",
      "Old friends are gold.\n",
      "New friends are silver.\n",
      "Make new friends keep old.\n",
      "One is silver other gold.\n",
      "A friend in need.\n",
      "Friendship is precious gift.\n",
      "Let's make a plan.\n",
      "We should schedule meeting.\n",
      "Put it on calendar.\n",
      "Set reminder for this.\n",
      "Don't forget please.\n",
      "Remember to call them.\n",
      "I almost forgot thanks.\n",
      "Glad you remembered that.\n",
      "Good memory you have.\n",
      "My memory is terrible.\n",
      "Senior moment I guess.\n",
      "Where are my keys?\n",
      "Has anyone seen phone?\n",
      "Right where you left.\n",
      "In your pocket check.\n",
      "Found it finally!\n",
      "Right under my nose.\n",
      "Hiding in plain sight.\n",
      "Right before your eyes.\n",
      "Clear as day now.\n",
      "Plain as night day.\n",
      "Bright as sunshine.\n",
      "Dark as midnight.\n",
      "Quiet as mouse.\n",
      "Quick as flash.\n",
      "Strong as ox.\n",
      "Busy as bee.\n",
      "Happy as clam.\n",
      "Free as bird.\n",
      "Mad as hatter.\n",
      "I'll be there in 5 minutes.\n",
      "Let's meet at 3 PM.\n",
      "I need 2 copies of this document.\n",
      "The recipe calls for 3 eggs.\n",
      "My apartment is number 25.\n",
      "She bought 4 new dresses.\n",
      "We have 7 days to finish.\n",
      "The team has 11 players.\n",
      "I waited for 30 minutes.\n",
      "He scored 98 points.\n",
      "My zip code is 90210.\n",
      "The meeting is on March 15.\n",
      "I was born in 1990.\n",
      "That will be 19.99.\n",
      "The temperature is 75 degrees.\n",
      "The store opens at 9 AM.\n",
      "The code is 7392.\n",
      "I read 3 books this month.\n",
      "We walked 5 miles today.\n",
      "The baby weighed 8 pounds.\n",
      "I need 10 more minutes.\n",
      "The sale ends in 2 hours.\n",
      "He has 20 years of experience.\n",
      "The building has 15 floors.\n",
      "I got 4 out of 5 correct.\n",
      "She ran 6 miles yesterday.\n",
      "The class has 24 students.\n"
     ]
    }
   ],
   "source": [
    "with open('../dataset/ds.txt', 'r') as file:\n",
    "    training_text = file.read()\n",
    "\n",
    "print(\"training text:\")\n",
    "print(training_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ee2f1fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique characters: ['\\n', ' ', '!', \"'\", ',', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '?', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "Total unique characters: 43\n",
      "\n",
      "Character to index mapping:\n",
      "  '\n",
      "' -> 0\n",
      "  ' ' -> 1\n",
      "  '!' -> 2\n",
      "  ''' -> 3\n",
      "  ',' -> 4\n",
      "  '.' -> 5\n",
      "  '0' -> 6\n",
      "  '1' -> 7\n",
      "  '2' -> 8\n",
      "  '3' -> 9\n",
      "\n",
      "Vocabulary size: 43\n",
      "\n",
      "Remaining characters (66):\n",
      " !',.0123456789?ABCDEFGHIJKLMNOPQRSTUVWYabcdefghijklmnopqrstuvwxyz\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    # Remove unwanted characters and normalize whitespace\n",
    "    cleaned = re.sub(r'[^a-zA-Z0-9\\s\\.\\!\\?\\,\\'\\-]', '', text)\n",
    "    cleaned = re.sub(r'\\s+', ' ', cleaned)\n",
    "    chars = sorted(set(cleaned))\n",
    "    print(f\"\\nRemaining characters ({len(chars)}):\")\n",
    "    print(''.join(chars))\n",
    "    return cleaned\n",
    "\n",
    "# Get all unique characters from our text\n",
    "chars = sorted(list(set(training_text.lower())))\n",
    "print(f\"Unique characters: {chars}\")\n",
    "print(f\"Total unique characters: {len(chars)}\")\n",
    "\n",
    "# Create mappings between characters and numbers\n",
    "char_to_idx = {char: idx for idx, char in enumerate(chars)}\n",
    "idx_to_char = {idx: char for idx, char in enumerate(chars)}\n",
    "\n",
    "print(\"\\nCharacter to index mapping:\")\n",
    "for char, idx in list(char_to_idx.items())[:10]:  # Show first 10\n",
    "    print(f\"  '{char}' -> {idx}\")\n",
    "\n",
    "vocab_size = len(chars)\n",
    "print(f\"\\nVocabulary size: {vocab_size}\")\n",
    "\n",
    "# Now clean the text\n",
    "training_text = clean_text(training_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a53983f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: 'hello'\n",
      "To indices: [24, 21, 28, 28, 31]\n",
      "Back to text: 'hello'\n"
     ]
    }
   ],
   "source": [
    "def text_to_indices(text):\n",
    "    \"\"\"Convert text string to list of numbers\"\"\"\n",
    "    return [char_to_idx[char] for char in text.lower()]\n",
    "\n",
    "def indices_to_text(indices):\n",
    "    \"\"\"Convert list of numbers back to text\"\"\"\n",
    "    return ''.join([idx_to_char[idx] for idx in indices])\n",
    "\n",
    "# Let's test our conversion\n",
    "test_text = \"hello\"\n",
    "test_indices = text_to_indices(test_text)\n",
    "converted_back = indices_to_text(test_indices)\n",
    "\n",
    "print(f\"Original: '{test_text}'\")\n",
    "print(f\"To indices: {test_indices}\")\n",
    "print(f\"Back to text: '{converted_back}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6d2acccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sequences shape: torch.Size([11225, 15])\n",
      "Targets shape: torch.Size([11225])\n",
      "\n",
      "First training example:\n",
      "Input: 'the quick brown'\n",
      "Target: ' '\n"
     ]
    }
   ],
   "source": [
    "def create_sequences(text_indices, seq_length=20):\n",
    "    \"\"\"\n",
    "    Create training examples where:\n",
    "    - Input: sequence of characters\n",
    "    - Output: next character in sequence\n",
    "    \"\"\"\n",
    "    sequences = []\n",
    "    next_chars = []\n",
    "    \n",
    "    # Slide a window through the text\n",
    "    for i in range(len(text_indices) - seq_length):\n",
    "        # Input sequence\n",
    "        seq = text_indices[i:i + seq_length]\n",
    "        # Target (next character after the sequence)\n",
    "        target = text_indices[i + seq_length]\n",
    "        \n",
    "        sequences.append(seq)\n",
    "        next_chars.append(target)\n",
    "    \n",
    "    return torch.tensor(sequences), torch.tensor(next_chars)\n",
    "\n",
    "# Convert our text to numbers\n",
    "text_indices = text_to_indices(training_text)\n",
    "\n",
    "# Create training data\n",
    "seq_length = 15  # We'll use 15 characters to predict the 16th\n",
    "X, y = create_sequences(text_indices, seq_length)\n",
    "\n",
    "print(f\"Input sequences shape: {X.shape}\")  # (num_sequences, seq_length)\n",
    "print(f\"Targets shape: {y.shape}\")         # (num_sequences,)\n",
    "\n",
    "# Let's look at one example\n",
    "print(f\"\\nFirst training example:\")\n",
    "input_seq = X[0]\n",
    "target_char = y[0]\n",
    "print(f\"Input: '{indices_to_text(input_seq.tolist())}'\")\n",
    "print(f\"Target: '{idx_to_char[target_char.item()]}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a1d435d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created!\n",
      "Parameters: 209,195\n"
     ]
    }
   ],
   "source": [
    "class AutocompleteRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, num_layers=2):\n",
    "        super(AutocompleteRNN, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # Embedding layer: converts character indices to dense vectors\n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
    "        \n",
    "        # GRU layer: our RNN that remembers patterns\n",
    "        self.gru = nn.GRU(\n",
    "            hidden_size, \n",
    "            hidden_size, \n",
    "            num_layers, \n",
    "            batch_first=True,\n",
    "            dropout=0.2\n",
    "        )\n",
    "        \n",
    "        # Output layer: predicts which character comes next\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "    \n",
    "    def forward(self, x, hidden=None):\n",
    "        # x shape: (batch_size, sequence_length)\n",
    "        \n",
    "        # Step 1: Convert character indices to vectors\n",
    "        embedded = self.embedding(x)  # (batch_size, seq_len, hidden_size)\n",
    "        \n",
    "        # Step 2: Pass through GRU (the RNN part)\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        \n",
    "        # Step 3: Get the last output and predict next character\n",
    "        output = self.fc(output[:, -1, :])  # Use only the last output\n",
    "        \n",
    "        return output, hidden\n",
    "\n",
    "# Let's create our model\n",
    "hidden_size = 128\n",
    "model = AutocompleteRNN(vocab_size, hidden_size).to(device)\n",
    "print(\"Model created!\")\n",
    "print(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "65c0818b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def autocomplete(model, start_text, max_length=50, temperature=0.8, seq_length=15):\n",
    "    \"\"\"Generate autocomplete suggestions - IMPROVED VERSION\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Convert start text to indices\n",
    "    start_indices = text_to_indices(start_text)\n",
    "    \n",
    "    # Handle short inputs by padding\n",
    "    if len(start_indices) < seq_length:\n",
    "        # We can either pad or use what we have\n",
    "        # Let's use what we have but warn the user\n",
    "        print(f\"Warning: Input '{start_text}' is shorter than sequence length {seq_length}\")\n",
    "        # We'll just use the available characters\n",
    "        current_sequence = start_indices\n",
    "    else:\n",
    "        # Use the last seq_length characters\n",
    "        current_sequence = start_indices[-seq_length:]\n",
    "    \n",
    "    generated = start_indices.copy()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Convert to tensor with correct shape: (batch_size=1, sequence_length)\n",
    "        current_seq = torch.tensor([current_sequence]).to(device)\n",
    "        print(f\"Starting with sequence: '{indices_to_text(current_sequence)}'\")\n",
    "        \n",
    "        for i in range(max_length):\n",
    "            # Forward pass\n",
    "            output, _ = model(current_seq)\n",
    "            \n",
    "            # Apply temperature\n",
    "            output = output / temperature\n",
    "            \n",
    "            # Get probabilities\n",
    "            probabilities = torch.softmax(output, dim=-1).cpu().numpy()[0]\n",
    "            \n",
    "            # Sample next character\n",
    "            next_char_idx = np.random.choice(len(probabilities), p=probabilities)\n",
    "            generated.append(next_char_idx)\n",
    "            \n",
    "            # Update sequence (sliding window)\n",
    "            new_sequence = generated[-seq_length:]\n",
    "            current_seq = torch.tensor([new_sequence]).to(device)\n",
    "            \n",
    "            # Optional: stop if we generate a newline or similar\n",
    "            if idx_to_char[next_char_idx] == '\\n':\n",
    "                break\n",
    "    \n",
    "    final_text = indices_to_text(generated)\n",
    "    print(f\"Final result: '{final_text}'\")\n",
    "    return final_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8d209d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing Fixed Autocomplete ===\n",
      "Input: 'hello' -> 'hello9xoi00!ujo ys3227fb6'\n",
      "Input: 'mach' -> 'machj.69cq2fi!j1'xyr6,mb'\n",
      "Input: 'neur' -> 'neur.f w5m7fg1yqxviw'2 7'\n",
      "Input: 'pyt' -> 'pyta5t96g0r'zq2\n",
      "rnop'9.'\n"
     ]
    }
   ],
   "source": [
    "def autocomplete_working(model, start_text, max_length=30, temperature=0.8):\n",
    "    \"\"\"Working autocomplete function\"\"\"\n",
    "    model.eval()\n",
    "    seq_length = 15\n",
    "    \n",
    "    # Convert to indices\n",
    "    start_indices = text_to_indices(start_text)\n",
    "    generated = start_indices.copy()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Handle sequence length\n",
    "        if len(start_indices) < seq_length:\n",
    "            # Pad with zeros (0 is usually space or most common char)\n",
    "            current_sequence = [0] * (seq_length - len(start_indices)) + start_indices\n",
    "        else:\n",
    "            current_sequence = start_indices[-seq_length:]\n",
    "        \n",
    "        current_seq = torch.tensor([current_sequence]).to(device)\n",
    "        \n",
    "        for i in range(max_length):\n",
    "            # Get prediction\n",
    "            output, _ = model(current_seq)\n",
    "            output = output / temperature\n",
    "            \n",
    "            # Convert to probabilities and sample\n",
    "            probabilities = torch.softmax(output, dim=-1).cpu().numpy()[0]\n",
    "            next_char_idx = np.random.choice(len(probabilities), p=probabilities)\n",
    "            \n",
    "            # Add to generated\n",
    "            generated.append(next_char_idx)\n",
    "            \n",
    "            # Update sequence (sliding window)\n",
    "            current_sequence = generated[-seq_length:]\n",
    "            current_seq = torch.tensor([current_sequence]).to(device)\n",
    "    \n",
    "    return indices_to_text(generated)\n",
    "\n",
    "# Test it!\n",
    "print(\"\\n=== Testing Fixed Autocomplete ===\")\n",
    "test_inputs = [\"hello\", \"mach\", \"neur\", \"pyt\"]\n",
    "\n",
    "for test_input in test_inputs:\n",
    "    completion = autocomplete_working(model, test_input, max_length=20, temperature=0.7)\n",
    "    print(f\"Input: '{test_input}' -> '{completion}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f024cad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸŽ¯ === INTERACTIVE AUTOCOMPLETE (FIXED) ===\n",
      "Type some text and see what the model suggests!\n",
      "You: hello\u001b[94mth5$56miub,mofobc: , i6dv2:o1$\u001b[0m\n",
      "You: what is\u001b[94m4.wqhtq/veqv5,2?rt\n",
      "d:1,7x6dm8y\u001b[0m\n",
      "Please type at least one character\n",
      "Please type at least one character\n",
      "You: f\u001b[94my2c43 gc!3v1-bz2ko1m7hhd's5/ g\u001b[0m\n",
      "You: football\u001b[94mj\n",
      "c1i/l9x-6,wu3jred2'vvi67muup\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moriginal_part\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\033\u001b[39;00m\u001b[38;5;124m[94m\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_part\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\033\u001b[39;00m\u001b[38;5;124m[0m\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Run the fixed demo\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m \u001b[43minteractive_demo_fixed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[14], line 6\u001b[0m, in \u001b[0;36minteractive_demo_fixed\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mType some text and see what the model suggests!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m----> 6\u001b[0m     user_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mStart typing: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m user_input\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquit\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m      9\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py:1275\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1273\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1274\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[1;32m-> 1275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1276\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1277\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1278\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1279\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1280\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py:1320\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1317\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1318\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m   1319\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1320\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1321\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1322\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "def interactive_demo_fixed():\n",
    "    \n",
    "    print(\"Type some text and see what the model suggests!\")\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"\\nStart typing: \").strip()\n",
    "        \n",
    "        if user_input.lower() == 'quit':\n",
    "            break\n",
    "        elif len(user_input) < 1:\n",
    "            print(\"Please type at least one character\")\n",
    "            continue\n",
    "        \n",
    "        completion = autocomplete_working(model, user_input, max_length=30, temperature=0.7)\n",
    "        \n",
    "        # Show the original input and the completion in different colors\n",
    "        original_part = completion[:len(user_input)]\n",
    "        new_part = completion[len(user_input):]\n",
    "        print(f\"You: {original_part}\\033[94m{new_part}\\033[0m\")\n",
    "\n",
    "# Run the fixed demo\n",
    "interactive_demo_fixed()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
